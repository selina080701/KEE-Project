# d_extract_locations_all_movies.py

import json
import re
import spacy
from geopy.geocoders import Nominatim
import time
import pandas as pd
from pathlib import Path

"""
This file extracts location names from the JSON files generated by the fandom_request_all_movies.py script.
It uses spaCy's Named Entity Recognition to identify places and then geocodes them using Nominatim.
    -> Input: JSON files in extract_knowledge/fandom_wiki_pages/ directory
    -> Output: CSV files in extract_knowledge/geocoded_locations/ directory
Step 1: Extract location names from relevant sections of the JSON files.
Step 2: Geocode the extracted location names to get latitude and longitude.
Step 3: Data cleaning: removes duplicates or empty geocoordinates and cleans text formatting.
"""

nlp = spacy.load("en_core_web_lg")
PLACE_LABELS = {"GPE", "LOC", "FAC"}

# ------------ Places Extraction ------------
def extract_places(input_text, movie_name):
    with open(input_text, "r", encoding="utf-8") as f:
        data = json.load(f)

    # Limit text search to specific fields
    sections = data.get("sections", {})

    locations_text = ""
    if "Locations" in sections:
        locations_text += str(sections["Locations"])
    if "Film locations" in sections:
        locations_text += str(sections["Film locations"])
    if "Shooting locations" in sections:
        locations_text += str(sections["Shooting locations"])
    
    if not locations_text:
        print(f"No location-related fields found in {movie_name}.")
        return []

    # Remove wiki link syntax [[...]] but keep the display text
    locations_text = re.sub(r"\[\[([^\]|]+)(\|[^\]]+)?\]\]", r"\1", locations_text)

    # spaCy Named Entity Recognition
    doc = nlp(locations_text)
    places = sorted(set(ent.text for ent in doc.ents if ent.label_ in PLACE_LABELS))
    return places

# ------------ Geocoding ------------
geolocator = Nominatim(user_agent="James_Bond_Universe_Geocoder")

def geocode_locations(locations, movie_name):
    coords = []
    for loc in locations:
        try:
            geo = geolocator.geocode(loc)
            if geo:
                coords.append({
                    "name": loc,
                    "lat": geo.latitude,
                    "lon": geo.longitude,
                    "movie": movie_name
                })
            time.sleep(1)
        except:
            pass

    return coords


# ------------ Post cleaning of geocoded data ------------
def data_cleaning(geocoded_data):
    """
    - remove duplicas, by movie and name
    - remove special characters from names such as brackets, quotes, pipes, etc.
    - remove entries with empty lat/lon if any
    """
    df = pd.DataFrame(geocoded_data)
    df.drop_duplicates(subset=["movie", "name"], inplace=True)
    df = df[df["lat"].notnull() & df["lon"].notnull()]

    # Clean names
    df["name"] = df["name"].str.replace(r"[\[\]\(\)\"\'\|]", "", regex=True).str.strip()
    
    return df


if __name__ == "__main__":
    base_dir = Path(__file__).resolve().parent.parent
    input_folder = base_dir / "extract_knowledge/fandom_wiki_pages"

    output_folder = base_dir / "extract_knowledge/geocoded_locations"
    output_folder.mkdir(exist_ok=True)

    all_geocoded = []
    json_files = list(input_folder.glob("*_film.json"))
    print(f"Found {len(json_files)} JSON files\n")
    
    for json_file in json_files:

        # Extract movie title from filename (e.g. "Licence_to_Kill_film.json" -> "Licence to Kill")
        movie_name = json_file.stem.replace("_film", "").replace("_", " ")
        print(f"Processing: {movie_name}")
        
        # Extract places
        raw_places = extract_places(input_text=json_file, movie_name=movie_name)
        print(f"Found {len(raw_places)} unique places")
        
        # Geocode places
        if raw_places:
            geo_locations = geocode_locations(locations=raw_places,

                                              movie_name=movie_name)
            all_geocoded.extend(geo_locations)
            print(f"Geocoded {len(geo_locations)} locations\n")
        else:
            print(f"No places to geocode\n")
    
    # Save all results to a CSV
    output_file = output_folder / "all_movies_geocoded.csv"
    df = pd.DataFrame(all_geocoded)

    # Post Data cleaning
    df_cleaned = data_cleaning(df)
    df_cleaned.to_csv(output_file, index=False)
    print(f"Saved cleaned geocoded data to {output_file}")